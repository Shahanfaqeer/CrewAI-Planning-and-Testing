{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOjv6NytygtSDfDUs0QWDF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahanfaqeer/CrewAI-Planning-and-Testing/blob/main/CREWAI_Planning_Crew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcY3reBVL_Q1",
        "outputId": "af70c761-19bb-4b46-e578-1928fc1c03ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.3/265.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.50.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
            "google-genai 1.7.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq crewai crewai-tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"Gemini_API_Key\"]=userdata.get(\"Gemini_API_Key\")\n",
        "os.environ[\"MODEL\"]=\"gemini/gemini-2.0-flash\"\n",
        "# os.environ[\"OPENAI_API_KEY\"]=userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "z0glAIRuMMIU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XJmR2VOuMYDL",
        "outputId": "f8764acf-f317-491f-d437-a218a90ea89e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gemini/gemini-2.0-flash'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Di8wlVuaMafb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!crewai create crew pr1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGJ0ZLzlMbEs",
        "outputId": "be5a57ec-6c07-42c8-9445-5c6acb6ed449"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1mCreating folder pr1...\u001b[0m\n",
            "\u001b[36mCache expired or not found. Fetching provider data from the web...\u001b[0m\n",
            "\r\u001b[?25lDownloading  [------------------------------------]  0/18605\r\u001b[?25lDownloading  [###############---------------------]  8192/18605\r\u001b[?25lDownloading  [###############################-----]  16384/18605\r\u001b[?25lDownloading  [####################################]  24576/18605\r\u001b[?25lDownloading  [####################################]  32768/18605\r\u001b[?25lDownloading  [####################################]  40960/18605\r\u001b[?25lDownloading  [####################################]  49152/18605\r\u001b[?25lDownloading  [####################################]  57344/18605\r\u001b[?25lDownloading  [####################################]  65536/18605\r\u001b[?25lDownloading  [####################################]  73728/18605\r\u001b[?25lDownloading  [####################################]  81920/18605\r\u001b[?25lDownloading  [####################################]  90112/18605\r\u001b[?25lDownloading  [####################################]  98304/18605\r\u001b[?25lDownloading  [####################################]  106496/18605\r\u001b[?25lDownloading  [####################################]  114688/18605\r\u001b[?25lDownloading  [####################################]  122880/18605\r\u001b[?25lDownloading  [####################################]  131072/18605\r\u001b[?25lDownloading  [####################################]  139264/18605\r\u001b[?25lDownloading  [####################################]  147456/18605\r\u001b[?25lDownloading  [####################################]  155648/18605\r\u001b[?25lDownloading  [####################################]  163840/18605\r\u001b[?25lDownloading  [####################################]  172032/18605\r\u001b[?25lDownloading  [####################################]  180224/18605\r\u001b[?25lDownloading  [####################################]  188416/18605\r\u001b[?25lDownloading  [####################################]  196608/18605\r\u001b[?25lDownloading  [####################################]  204800/18605\r\u001b[?25lDownloading  [####################################]  212992/18605\r\u001b[?25lDownloading  [####################################]  221184/18605\r\u001b[?25lDownloading  [####################################]  229376/18605\r\u001b[?25lDownloading  [####################################]  237568/18605\r\u001b[?25lDownloading  [####################################]  245760/18605\r\u001b[?25lDownloading  [####################################]  253952/18605\r\u001b[?25lDownloading  [####################################]  262144/18605\r\u001b[?25lDownloading  [####################################]  270336/18605\r\u001b[?25lDownloading  [####################################]  278528/18605\r\u001b[?25lDownloading  [####################################]  286720/18605\r\u001b[?25lDownloading  [####################################]  294912/18605\r\u001b[?25lDownloading  [####################################]  303104/18605\r\u001b[?25lDownloading  [####################################]  311296/18605\r\u001b[?25lDownloading  [####################################]  319488/18605\r\u001b[?25lDownloading  [####################################]  327680/18605\r\u001b[?25lDownloading  [####################################]  335872/18605\r\u001b[?25lDownloading  [####################################]  344064/18605\r\u001b[?25lDownloading  [####################################]  352256/18605\r\u001b[?25lDownloading  [####################################]  360448/18605\r\u001b[?25lDownloading  [####################################]  368640/18605\r\u001b[?25lDownloading  [####################################]  376832/18605\r\u001b[?25lDownloading  [####################################]  385024/18605\r\u001b[?25lDownloading  [####################################]  387938/18605\u001b[?25h\n",
            "\u001b[36mSelect a provider to set up:\u001b[0m\n",
            "\u001b[36m1. openai\u001b[0m\n",
            "\u001b[36m2. anthropic\u001b[0m\n",
            "\u001b[36m3. gemini\u001b[0m\n",
            "\u001b[36m4. nvidia_nim\u001b[0m\n",
            "\u001b[36m5. groq\u001b[0m\n",
            "\u001b[36m6. ollama\u001b[0m\n",
            "\u001b[36m7. watson\u001b[0m\n",
            "\u001b[36m8. bedrock\u001b[0m\n",
            "\u001b[36m9. azure\u001b[0m\n",
            "\u001b[36m10. cerebras\u001b[0m\n",
            "\u001b[36m11. sambanova\u001b[0m\n",
            "\u001b[36m12. other\u001b[0m\n",
            "\u001b[36mq. Quit\u001b[0m\n",
            "Enter the number of your choice or 'q' to quit: 3\n",
            "\u001b[36mSelect a model to use for Gemini:\u001b[0m\n",
            "\u001b[36m1. gemini/gemini-1.5-flash\u001b[0m\n",
            "\u001b[36m2. gemini/gemini-1.5-pro\u001b[0m\n",
            "\u001b[36m3. gemini/gemini-gemma-2-9b-it\u001b[0m\n",
            "\u001b[36m4. gemini/gemini-gemma-2-27b-it\u001b[0m\n",
            "\u001b[36mq. Quit\u001b[0m\n",
            "Enter the number of your choice or 'q' to quit: 1\n",
            "Enter your GEMINI API key (press Enter to skip): AIzaSyBftRmHoAXmRurnoXuoLNPPRmfOnt2HzWY\n",
            "\u001b[32mAPI keys and model saved to .env file\u001b[0m\n",
            "\u001b[32mSelected model: gemini/gemini-1.5-flash\u001b[0m\n",
            "\u001b[32m  - Created pr1/.gitignore\u001b[0m\n",
            "\u001b[32m  - Created pr1/pyproject.toml\u001b[0m\n",
            "\u001b[32m  - Created pr1/README.md\u001b[0m\n",
            "\u001b[32m  - Created pr1/knowledge/user_preference.txt\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/__init__.py\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/main.py\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/crew.py\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/tools/custom_tool.py\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/tools/__init__.py\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/config/agents.yaml\u001b[0m\n",
            "\u001b[32m  - Created pr1/src/pr1/config/tasks.yaml\u001b[0m\n",
            "\u001b[32m\u001b[1mCrew pr1 created successfully!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd  #present working directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp56xBVEMzDk",
        "outputId": "6dee5d9b-45d6-4063-d370-bdaa0eb70712"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pr1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e03M5GIjM2Qp",
        "outputId": "d2554b07-0e48-496b-d4b6-80ad6db7a386"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pr1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6YVcPisM6Tq",
        "outputId": "b383dca9-e439-4306-d1e9-1ffa0caef63c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knowledge  pyproject.toml  README.md  src  tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!crewai run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnQ8yuohM87f",
        "outputId": "e250ed70-d218-441a-b993-095f5998c0eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the crew for 2 iterations with model gpt-4o-mini\n",
            "WARNING:opentelemetry.attributes:Invalid type LLM for attribute 'model_name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
            "\n",
            "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m Test Execution \u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
            "\u001b[34m│\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
            "\u001b[34m│\u001b[0m  \u001b[1;34m🧪 Starting Crew Test\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
            "\u001b[34m│\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
            "\u001b[34m│\u001b[0m  \u001b[37mCrew: \u001b[0m\u001b[34mcrew\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
            "\u001b[34m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[34m8d6b5300-cfdb-4cc1-9401-8f56cb7ece55\u001b[0m                                                        \u001b[34m│\u001b[0m\n",
            "\u001b[34m│\u001b[0m  \u001b[37mIterations: \u001b[0m\u001b[33m2\u001b[0m                                                                                   \u001b[34m│\u001b[0m\n",
            "\u001b[34m│\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
            "\u001b[34m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1;34m🧪 Test: \u001b[0m\u001b[34mcrew\u001b[0m\n",
            "\u001b[37m    Status: \u001b[0m\u001b[33mIn Progress\u001b[0m\n",
            "└── \u001b[33m🔄 Running tests...\u001b[0m\n",
            "\n",
            "\u001b[36m╭─\u001b[0m\u001b[36m────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
            "\u001b[36m│\u001b[0m                                                                                                  \u001b[36m│\u001b[0m\n",
            "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                          \u001b[36m│\u001b[0m\n",
            "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                      \u001b[36m│\u001b[0m\n",
            "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36mab1aad83-081b-4efc-b7a4-1557d8afd21a\u001b[0m                                                        \u001b[36m│\u001b[0m\n",
            "\u001b[36m│\u001b[0m                                                                                                  \u001b[36m│\u001b[0m\n",
            "\u001b[36m│\u001b[0m                                                                                                  \u001b[36m│\u001b[0m\n",
            "\u001b[36m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "        \n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mConduct a thorough research about AI LLMs Make sure you find any interesting and relevant information given the current year is 2025.\n",
            "\u001b[00m\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "        \n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "        └── \u001b[1;34m🧠 \u001b[0m\u001b[34mThinking...\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "        \n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Here are 10 key developments and relevant information about AI LLMs in 2025:\n",
            "\n",
            "*   **Ubiquitous Multimodal LLMs:** LLMs have evolved beyond text to seamlessly integrate and process multiple modalities like images, audio, video, and sensor data. This allows for richer, more contextualized interactions and applications, such as AI assistants that can understand and respond to real-world environments through camera feeds and microphones.\n",
            "\n",
            "*   **Personalized and Adaptive LLMs:** LLMs are now highly personalized, adapting to individual user preferences, cognitive styles, and knowledge levels. Through continuous learning and fine-tuning on user-specific data, these models provide tailored responses and experiences, improving user engagement and satisfaction. This includes personalized education, therapy, and creative content generation.\n",
            "\n",
            "*   **Advanced Reasoning and Problem-Solving Capabilities:** LLMs have made significant strides in reasoning and problem-solving. They can handle complex tasks such as scientific discovery, strategic planning, and ethical decision-making by leveraging advanced algorithms and knowledge representation techniques. This has led to breakthroughs in fields like drug discovery, climate modeling, and financial analysis.\n",
            "\n",
            "*   **Explainable AI (XAI) Integration:** Transparency and interpretability are paramount. LLMs now incorporate XAI techniques, providing detailed explanations for their decisions and actions. This fosters trust and accountability, particularly in sensitive domains like healthcare and finance, where understanding the reasoning behind AI outputs is crucial.\n",
            "\n",
            "*   **Federated Learning for LLMs:** To address data privacy concerns, federated learning has become a standard approach for training LLMs. This allows models to learn from decentralized data sources without directly accessing or sharing sensitive information. This has enabled collaborative AI development across organizations and industries while preserving user privacy.\n",
            "\n",
            "*   **LLMs for Code Generation and Software Development:** LLMs have revolutionized software development by automating code generation, debugging, and testing. They can understand natural language instructions and translate them into functional code, significantly increasing developer productivity and reducing development time. Furthermore, LLMs assist in identifying and fixing security vulnerabilities.\n",
            "\n",
            "*   **LLMs in Healthcare and Medical Diagnosis:** LLMs play a crucial role in healthcare, assisting with medical diagnosis, treatment planning, and drug discovery. They can analyze medical records, research papers, and clinical trial data to provide insights and recommendations to healthcare professionals, improving patient outcomes and reducing medical errors.\n",
            "\n",
            "*   **Ethical Considerations and Bias Mitigation:** LLMs are actively being developed with built-in safeguards to mitigate biases and promote fairness. Ethical guidelines and regulations are in place to ensure that AI systems are used responsibly and do not perpetuate discrimination or harm. Research focuses on developing bias detection and mitigation techniques to create more equitable AI models.\n",
            "\n",
            "*   **Quantum-Enhanced LLMs:** Early integrations of quantum computing principles are starting to enhance LLM capabilities for specific tasks. While full-scale quantum LLMs are still in the future, quantum-inspired algorithms and hybrid architectures are improving performance in areas like optimization and pattern recognition.\n",
            "\n",
            "*   **Democratization of LLM Access:** LLMs are becoming increasingly accessible to a wider range of users through cloud-based platforms and open-source initiatives. This democratization allows individuals and organizations with limited resources to leverage the power of AI for various applications, fostering innovation and creativity across different sectors.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "        \n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "├── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "│   \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "│   └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│       \n",
            "│       \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: e8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "├── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "│   \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "│   └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│       \n",
            "│       \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: e8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mTask Execution Evaluator\u001b[0m\n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "├── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "│   \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "│   └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│       \n",
            "│       \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: e8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mTask Execution Evaluator\u001b[0m\n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "        └── \u001b[1;34m🧠 \u001b[0m\u001b[34mThinking...\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "├── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "│   \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "│   └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│       \n",
            "│       \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "└── \u001b[1;33m📋 Task: e8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mTask Execution Evaluator\u001b[0m\n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "        └── \u001b[1;31m❌ LLM Failed\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────────────────\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31m───────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[1;31m❌ LLM Call Failed\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mlitellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': \u001b[0m   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[31m{'message': 'You exceeded your current quota, please check your plan and billing details. For \u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[31mmore information on this error, read the docs: \u001b[0m                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[31mhttps://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': \u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[31m'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\u001b[0m                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "\u001b[91m Error during LLM call: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\u001b[00m\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "├── \u001b[1;33m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "│   \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
            "│   └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│       \n",
            "│       \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "└── \u001b[1;31m📋 Task: e8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m\n",
            "    \u001b[37m   Assigned to: \u001b[0m\u001b[31mTask Execution Evaluator\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[1;31m❌ Failed\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mTask Execution Evaluator\u001b[0m\n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "        └── \u001b[1;31m❌ LLM Failed\u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31me8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mTask Execution Evaluator\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[1;36m🚀 Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
            "├── \u001b[1;31m📋 Task: d01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m\n",
            "│   \u001b[37m   Assigned to: \u001b[0m\u001b[31mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│   \n",
            "│   \u001b[37m   Status: \u001b[0m\u001b[1;31m❌ Failed\u001b[0m\n",
            "│   └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mAI LLMs Senior Data Researcher\u001b[0m\n",
            "│       \n",
            "│       \u001b[37m    Status: \u001b[0m\u001b[1;32m✅ Completed\u001b[0m\n",
            "└── \u001b[1;31m📋 Task: e8921b65-79c1-46fe-a4e6-dc26ed438eb1\u001b[0m\n",
            "    \u001b[37m   Assigned to: \u001b[0m\u001b[31mTask Execution Evaluator\u001b[0m\n",
            "    \u001b[37m   Status: \u001b[0m\u001b[1;31m❌ Failed\u001b[0m\n",
            "    └── \u001b[1;32m🤖 Agent: \u001b[0m\u001b[32mTask Execution Evaluator\u001b[0m\n",
            "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
            "        └── \u001b[1;31m❌ LLM Failed\u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31md01efb49-7fdd-4db0-8ba3-3f4a580f51e4\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mAI LLMs Senior Data Researcher\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m Crew Failure \u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[1;31mCrew Execution Failed\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[31mab1aad83-081b-4efc-b7a4-1557d8afd21a\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m Test Failure \u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[1;31m❌ Crew Test Failed\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m  \u001b[37mCrew: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 711, in completion\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 638, in completion\n",
            "    self.make_sync_openai_chat_completion_request(\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 145, in sync_wrapper\n",
            "    result = func(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 457, in make_sync_openai_chat_completion_request\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 439, in make_sync_openai_chat_completion_request\n",
            "    raw_response = openai_client.chat.completions.with_raw_response.create(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
            "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1242, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 919, in request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1008, in _request\n",
            "    return self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1057, in _retry_request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1008, in _request\n",
            "    return self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1057, in _retry_request\n",
            "    return self._request(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1023, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/main.py\", line 1692, in completion\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/main.py\", line 1665, in completion\n",
            "    response = openai_chat_completions.completion(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 721, in completion\n",
            "    raise OpenAIError(\n",
            "litellm.llms.openai.common_utils.OpenAIError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pr1/src/pr1/main.py\", line 47, in test\n",
            "    Pr1().crew().test(\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/crew.py\", line 1240, in test\n",
            "    test_crew.kickoff(inputs=inputs)\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/crew.py\", line 640, in kickoff\n",
            "    result = self._run_sequential_process()\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/crew.py\", line 752, in _run_sequential_process\n",
            "    return self._execute_tasks(self.tasks)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/crew.py\", line 850, in _execute_tasks\n",
            "    task_output = task.execute_sync(\n",
            "                  ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/task.py\", line 310, in execute_sync\n",
            "    return self._execute_core(agent, context, tools)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/task.py\", line 454, in _execute_core\n",
            "    raise e  # Re-raise the exception after emitting the event\n",
            "    ^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/task.py\", line 434, in _execute_core\n",
            "    self.callback(self.output)\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/utilities/evaluators/crew_evaluator_handler.py\", line 178, in evaluate\n",
            "    evaluation_result = evaluation_task.execute_sync()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/task.py\", line 310, in execute_sync\n",
            "    return self._execute_core(agent, context, tools)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/task.py\", line 454, in _execute_core\n",
            "    raise e  # Re-raise the exception after emitting the event\n",
            "    ^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/task.py\", line 374, in _execute_core\n",
            "    result = agent.execute_task(\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agent.py\", line 266, in execute_task\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agent.py\", line 247, in execute_task\n",
            "    result = self.agent_executor.invoke(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 119, in invoke\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 108, in invoke\n",
            "    formatted_answer = self._invoke_loop()\n",
            "                       ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 166, in _invoke_loop\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 146, in _invoke_loop\n",
            "    answer = self._get_llm_response()\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 216, in _get_llm_response\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 207, in _get_llm_response\n",
            "    answer = self.llm.call(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/llm.py\", line 739, in call\n",
            "    return self._handle_non_streaming_response(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/crewai/llm.py\", line 575, in _handle_non_streaming_response\n",
            "    response = litellm.completion(**params)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/utils.py\", line 1154, in wrapper\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/utils.py\", line 1032, in wrapper\n",
            "    result = original_function(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/main.py\", line 3068, in completion\n",
            "    raise exception_type(\n",
            "          ^^^^^^^^^^^^^^^\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2201, in exception_type\n",
            "    raise e\n",
            "  File \"/content/pr1/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 425, in exception_type\n",
            "    raise RateLimitError(\n",
            "litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pr1/.venv/bin/test\", line 10, in <module>\n",
            "    sys.exit(test())\n",
            "             ^^^^^^\n",
            "  File \"/content/pr1/src/pr1/main.py\", line 53, in test\n",
            "    raise Exception(f\"An error occurred while testing the crew: {e}\")\n",
            "Exception: An error occurred while testing the crew: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "An error occurred while testing the crew: Command '['uv', 'run', 'test', '2', 'gpt-4o-mini']' returned non-zero exit status 1.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}